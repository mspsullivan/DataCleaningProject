{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzKSumOy6T89GampSd4rk7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mspsullivan/DataCleaningProject/blob/master/get_started_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9dxP-4zUptrJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The script demonstrates a simple example of using ART with TensorFlow v1.x. The example train a small model on the MNIST\n",
        "dataset and creates adversarial examples using the Fast Gradient Sign Method. Here we use the ART classifier to train\n",
        "the model, it would also be possible to provide a pretrained model to the ART classifier.\n",
        "The parameters are chosen for reduced computational requirements of the script and not optimised for accuracy.\n",
        "\"\"\"\n",
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()  # Added to prevent Tensorflow execution error\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import TensorFlowClassifier\n",
        "from art.utils import load_mnist\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install adversarial-robustness-toolbox\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkeAEUABsZTs",
        "outputId": "57a9d0d5-883e-4720-ec7b-19bcc00084a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.13.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.2.0)\n",
            "Installing collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# Step 2: Create the model\n",
        "\n",
        "input_ph = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
        "labels_ph = tf.placeholder(tf.int32, shape=[None, 10])\n",
        "\n",
        "x = tf.layers.conv2d(input_ph, filters=4, kernel_size=5, activation=tf.nn.relu)\n",
        "x = tf.layers.max_pooling2d(x, 2, 2)\n",
        "x = tf.layers.conv2d(x, filters=10, kernel_size=5, activation=tf.nn.relu)\n",
        "x = tf.layers.max_pooling2d(x, 2, 2)\n",
        "x = tf.layers.flatten(x)\n",
        "x = tf.layers.dense(x, 100, activation=tf.nn.relu)\n",
        "logits = tf.layers.dense(x, 10)\n",
        "\n",
        "loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=labels_ph))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "train = optimizer.minimize(loss)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHiJkW-mrqYf",
        "outputId": "8a50dde1-c892-4a4b-fd74-e43cd6d35654"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-95ad993046fc>:10: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  x = tf.layers.conv2d(input_ph, filters=4, kernel_size=5, activation=tf.nn.relu)\n",
            "<ipython-input-9-95ad993046fc>:11: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "  x = tf.layers.max_pooling2d(x, 2, 2)\n",
            "<ipython-input-9-95ad993046fc>:12: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  x = tf.layers.conv2d(x, filters=10, kernel_size=5, activation=tf.nn.relu)\n",
            "<ipython-input-9-95ad993046fc>:13: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "  x = tf.layers.max_pooling2d(x, 2, 2)\n",
            "<ipython-input-9-95ad993046fc>:14: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  x = tf.layers.flatten(x)\n",
            "<ipython-input-9-95ad993046fc>:15: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  x = tf.layers.dense(x, 100, activation=tf.nn.relu)\n",
            "<ipython-input-9-95ad993046fc>:16: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  logits = tf.layers.dense(x, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "sJmV-jAzrfsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create the ART classifier\n",
        "\n",
        "classifier = TensorFlowClassifier(\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    input_ph=input_ph,\n",
        "    output=logits,\n",
        "    labels_ph=labels_ph,\n",
        "    train=train,\n",
        "    loss=loss,\n",
        "    learning=None,\n",
        "    sess=sess,\n",
        "    preprocessing_defences=[],\n",
        ")\n",
        "\n",
        "# Step 4: Train the ART classifier\n",
        "\n",
        "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)\n",
        "\n",
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Step 6: Generate adversarial test examples\n",
        "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "x_test_adv = attack.generate(x=x_test)\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "id": "8seOnYlZrhZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}